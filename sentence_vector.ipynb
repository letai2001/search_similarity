{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at VoVanPhuc/sup-SimCSE-VietNamese-phobert-base were not used when initializing RobertaModel: ['mlp.dense.bias', 'mlp.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pyvi import ViTokenizer\n",
    "import json\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Tải tokenizer và model SimCSE\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # Lấy embedding của token [CLS]\n",
    "    return embeddings.squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=\"http://localhost:6333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content_test_newquery_filter_media.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"\"\"Người dân địa phương đã cứu hộ thành công một bé gái 5 tuổi bị lạc trong rừng suốt hai ngày. Lực lượng cứu hộ đã phối hợp với các cơ quan chức năng và người dân quanh vùng để tìm kiếm và đưa bé về nhà an toàn.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Người dân địa_phương đã cứu_hộ thành_công một bé gái 5 tuổi bị lạc trong rừng suốt hai ngày . Lực_lượng cứu_hộ đã phối_hợp với các cơ_quan_chức_năng và người dân quanh vùng để tìm_kiếm và đưa bé về nhà an_toàn .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViTokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_text(ViTokenizer.tokenize(text)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text(ViTokenizer.tokenize(item['content'])).tolist(),  # Vector hóa 'content'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"content_vectors\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  \n",
    "        distance=models.Distance.COSINE \n",
    "    ),\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(always_ram=True),  \n",
    "    ),\n",
    "    hnsw_config=models.HnswConfigDiff(\n",
    "        m=32,  \n",
    "        ef_construct=100,  \n",
    "        full_scan_threshold=10000  \n",
    "    ),\n",
    "    optimizers_config=models.OptimizersConfigDiff(\n",
    "        default_segment_number=5,  # Số segment mặc định\n",
    "        indexing_threshold=0,  # Lập chỉ mục ngay lập tức cho mỗi vector mới\n",
    "    ),\n",
    "    on_disk_payload=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"title_vectors\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  \n",
    "        distance=models.Distance.COSINE  \n",
    "    ),\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(always_ram=True),  \n",
    "    ),\n",
    "    hnsw_config=models.HnswConfigDiff(\n",
    "        m=32,  \n",
    "        ef_construct=100,  \n",
    "        full_scan_threshold=10000  \n",
    "    ),\n",
    "    optimizers_config=models.OptimizersConfigDiff(\n",
    "        default_segment_number=5, \n",
    "        indexing_threshold=0,  \n",
    "    ),\n",
    "    on_disk_payload=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m----> 2\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     title \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Mã hóa content và title thành vector\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m----> 2\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     title \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Mã hóa content và title thành vector\u001b[39;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   1973\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 1976\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1978\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   1981\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_mpl_hook()\n\u001b[0;32m   2010\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2011\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2013\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "for item in data:\n",
    "    content = item['_source']['content']\n",
    "    title = item['_source']['title']\n",
    "    \n",
    "    # Mã hóa content và title thành vector\n",
    "    content_vector = encode_text(ViTokenizer.tokenize(content))\n",
    "    title_vector = encode_text(ViTokenizer.tokenize(title))\n",
    "    \n",
    "    # Tạo UUID cho content và title\n",
    "    content_id = str(uuid.uuid4())  # Tạo UUID cho content\n",
    "    title_id = str(uuid.uuid4())  # Tạo UUID cho title\n",
    "    \n",
    "    # Thêm content vào collection 'content_vectors'\n",
    "    client.upsert(\n",
    "        collection_name=\"content_vectors\",\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=content_id,  # Sử dụng UUID hợp lệ\n",
    "                vector=content_vector.tolist(),  # Vector hóa 'content'\n",
    "                payload={\"article_id\": item[\"_id\"]}  # Lưu ID bài viết trong payload\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Thêm title vào collection 'title_vectors'\n",
    "    client.upsert(\n",
    "        collection_name=\"title_vectors\",\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=title_id,  # Sử dụng UUID hợp lệ cho title\n",
    "                vector=title_vector.tolist(),  # Vector hóa 'title'\n",
    "                payload={\"article_id\": item[\"_id\"]}  # Lưu ID bài viết trong payload\n",
    "            )\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n",
      "Một batch đã hoàn thành.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Hàm để thực hiện batch upsert\n",
    "def batch_upsert(content_batch, title_batch):\n",
    "    content_points = [\n",
    "        models.PointStruct(\n",
    "            id=str(uuid.uuid4()),  # Tạo UUID cho content\n",
    "            vector=encode_text(ViTokenizer.tokenize(item['content'])).tolist(),  # Vector hóa 'content'\n",
    "            payload={\"article_id\": item[\"_id\"]}  # Lưu ID bài viết trong payload\n",
    "        )\n",
    "        for i, item in enumerate(content_batch)\n",
    "    ]\n",
    "    \n",
    "    title_points = [\n",
    "        models.PointStruct(\n",
    "            id=str(uuid.uuid4()),  # Tạo UUID cho title\n",
    "            vector=encode_text(ViTokenizer.tokenize(item['title'])).tolist(),  # Vector hóa 'title'\n",
    "            payload={\"article_id\": item[\"_id\"]}  # Lưu ID bài viết trong payload\n",
    "        )\n",
    "        for i, item in enumerate(title_batch)\n",
    "    ]\n",
    "    \n",
    "    # Thực hiện upsert cho cả content và title\n",
    "    client.upsert(collection_name=\"content_vectors\", points=content_points)\n",
    "    client.upsert(collection_name=\"title_vectors\", points=title_points)\n",
    "\n",
    "# Chia dữ liệu thành các batch\n",
    "batch_size = 100  # Chọn kích thước batch hợp lý\n",
    "batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "# Dùng ThreadPoolExecutor để chạy song song các batch\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = []\n",
    "    \n",
    "    for batch in batches:\n",
    "        content_batch = [{\"_id\": item[\"_id\"], \"content\": item[\"_source\"][\"content\"]} for item in batch]\n",
    "        title_batch = [{\"_id\": item[\"_id\"], \"title\": item[\"_source\"][\"title\"]} for item in batch]\n",
    "        \n",
    "        # Thực hiện batch upsert trong các luồng song song\n",
    "        futures.append(executor.submit(batch_upsert, content_batch, title_batch))\n",
    "    \n",
    "    # Dùng as_completed để theo dõi tiến trình của các batch\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()  # Có thể kiểm tra lỗi nếu cần\n",
    "            print(\"Một batch đã hoàn thành.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi xảy ra: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng vectors trong collection 'words': 2400\n"
     ]
    }
   ],
   "source": [
    "collection_info = client.get_collection(collection_name=\"content_vectors\")\n",
    "\n",
    "print(f\"Số lượng vectors trong collection 'words': {collection_info.points_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n",
      "Batch completed.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np\n",
    "\n",
    "# Kết nối tới Qdrant server\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Hàm thêm dữ liệu vào Qdrant\n",
    "def batch_upsert(points_batch, collection_name):\n",
    "    points = [\n",
    "        models.PointStruct(\n",
    "            id=point[\"id\"],\n",
    "            vector=point[\"vector\"],\n",
    "            payload={\"article_id\": point[\"id\"]}  # Tùy thuộc vào payload bạn muốn thêm\n",
    "        )\n",
    "        for point in points_batch\n",
    "    ]\n",
    "    client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Đọc file và chuẩn bị dữ liệu\n",
    "def read_vectors_from_file(file_path):\n",
    "    points = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            article_id = parts[0]\n",
    "            vector = np.array(list(map(float, parts[1:])))\n",
    "            points.append({\"id\": article_id, \"vector\": vector})\n",
    "    return points\n",
    "\n",
    "# Hàm chia dữ liệu thành các batch\n",
    "def split_batches(data, batch_size):\n",
    "    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "# Đường dẫn đến file chứa ID và vector\n",
    "file_path = 'contents_vectors.txt'\n",
    "\n",
    "# Đọc toàn bộ dữ liệu từ file\n",
    "all_points = read_vectors_from_file(file_path)\n",
    "\n",
    "# Chia dữ liệu thành các batch (ví dụ: 100 vector mỗi batch)\n",
    "batch_size = 100\n",
    "batches = split_batches(all_points, batch_size)\n",
    "\n",
    "# Sử dụng ThreadPoolExecutor để thêm dữ liệu song song\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = []\n",
    "    for batch in batches:\n",
    "        futures.append(executor.submit(batch_upsert, batch, \"content_vectors\"))  # Thêm vào collection contents\n",
    "        # futures.append(executor.submit(batch_upsert, batch, \"titles\"))  # Thêm vào collection titles\n",
    "    \n",
    "    # Theo dõi tiến trình của các batch\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            print(\"Batch completed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi xảy ra: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at VoVanPhuc/sup-SimCSE-VietNamese-phobert-base were not used when initializing RobertaModel: ['mlp.dense.bias', 'mlp.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "\n",
    "# Kết nối tới Qdrant server\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Tải PhoBERT model và tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\")\n",
    "\n",
    "\n",
    "# Hàm mã hóa văn bản thành vector sử dụng PhoBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Article ID: 0c7c40975bc054caca743b767f7eae3f, Similarity Score: 0.5885566\n",
      "2. Article ID: a7dc0d28978535360cc6367ca93ec925, Similarity Score: 0.5326917\n",
      "3. Article ID: 2f50b89af15c090664b6d8f44a58de5f, Similarity Score: 0.5222285\n",
      "4. Article ID: ee3bed7a6eb038b6d313d5d3bbee410c, Similarity Score: 0.5187587\n",
      "5. Article ID: 8b4649fc71cdccf59af89e1a75b17a15, Similarity Score: 0.49611023\n",
      "6. Article ID: 57f55ca44016c031c886a67a62d56f43, Similarity Score: 0.49611023\n",
      "7. Article ID: 495adcf627f969fca990cd02e1d42a78, Similarity Score: 0.48978072\n",
      "8. Article ID: aefec3490a6f2fe2052507f45b8c362c, Similarity Score: 0.48585397\n",
      "9. Article ID: 07674ac676362abda2e274e73dc374a7, Similarity Score: 0.48241717\n",
      "10. Article ID: 571eb76c8ad9a45eef52cb7a89b642bc, Similarity Score: 0.4807526\n"
     ]
    }
   ],
   "source": [
    "def encode_text(text, max_length=128):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # Vector từ token [CLS]\n",
    "    return embeddings.squeeze().cpu().numpy()\n",
    "\n",
    "# Hàm tìm kiếm các văn bản tương tự\n",
    "def find_similar_texts(input_text, collection_name=\"content_vectors\", limit=10):\n",
    "    # Mã hóa đoạn văn bản đầu vào thành vector\n",
    "    input_vector = encode_text(tokenize(input_text))\n",
    "    \n",
    "    # Gửi truy vấn tới Qdrant để tìm các vector tương tự\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=input_vector,\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    # Trả về các bài viết tương tự\n",
    "    similar_texts = []\n",
    "    for result in search_result:\n",
    "        article_id = result.payload.get(\"article_id\", \"Unknown\")\n",
    "        score = result.score\n",
    "        similar_texts.append({\"article_id\": article_id, \"score\": score})\n",
    "    \n",
    "    return similar_texts\n",
    "\n",
    "# Ví dụ về đoạn văn bản đầu vào\n",
    "input_text = \"công an hối lộ\"\n",
    "\n",
    "# Tìm kiếm 10 văn bản tương tự\n",
    "similar_articles = find_similar_texts(input_text)\n",
    "\n",
    "# In kết quả\n",
    "for idx, article in enumerate(similar_articles):\n",
    "    print(f\"{idx + 1}. Article ID: {article['article_id']}, Similarity Score: {article['score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
